{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SCCSMARTCODE/Deep-Learning-00/blob/main/Cifar10_DataLoader/cifar_data_loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsblsjwJ8dQT"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "import torch\n",
        "import tarfile\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq2O_I8H6qk_"
      },
      "outputs": [],
      "source": [
        "class LoadCifar10:\n",
        "    \"\"\"\n",
        "    This class loads our Cifar 10 dataset\n",
        "    \"\"\"\n",
        "    file_path=\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    file_name=\"zip_cifar_10.tar.gz\"\n",
        "\n",
        "\n",
        "    def __init__(self, root, download=False, transforms=None, train=True):\n",
        "        self.root = root\n",
        "        self.download = download\n",
        "        self.transforms = []\n",
        "        if transforms:\n",
        "            try:\n",
        "                self.transforms.extend(transforms)\n",
        "            except:\n",
        "                self.transforms.append(transforms)\n",
        "        self.train = train\n",
        "        self.dataset_folder = os.path.join(self.root, \"cifar-10-batches-py\")\n",
        "        self.dataset=[]\n",
        "\n",
        "        if not root:\n",
        "            return None\n",
        "\n",
        "        # download if self.download is True\n",
        "        if self.download:\n",
        "            self.download_dataset()\n",
        "\n",
        "        # loading dataset\n",
        "        if not os.path.exists(self.dataset_folder):\n",
        "            print(\"File doesn't exist\\nset download to True to download it\")\n",
        "            return None\n",
        "\n",
        "        # locate the necessary file based on requirement\n",
        "        if self.train:\n",
        "            file_names = [x for x in os.listdir(self.dataset_folder) if \"data_batch\" in x]\n",
        "        else:\n",
        "            file_names = [x for x in os.listdir(self.dataset_folder) if \"test_batch\" in x]\n",
        "\n",
        "        # convert the files to useable data\n",
        "        for file_name in file_names:\n",
        "            out = self.unpickle(os.path.join(self.dataset_folder, file_name))\n",
        "            batch_images = list(out.get(b'data'))\n",
        "            batch_images = map(self.format_image, batch_images)\n",
        "\n",
        "            batch_dataset = list(zip(batch_images, out.get(b'labels')))\n",
        "\n",
        "            self.dataset.extend(batch_dataset)\n",
        "\n",
        "\n",
        "    def download_dataset(self):\n",
        "        \"\"\"\n",
        "        This is the function that downloads and extract the cifar10 dataset from the main website\n",
        "        \"\"\"\n",
        "\n",
        "        if os.path.exists(self.dataset_folder):\n",
        "            print(\"File exists...\")\n",
        "            return\n",
        "        response = requests.get(self.file_path)\n",
        "        if response.status_code != 404:\n",
        "            downloaded_file_path = os.path.join(self.root, self.file_name)\n",
        "            with open(downloaded_file_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "        else:\n",
        "            print(\"File Not Found\")\n",
        "            exit(-1)\n",
        "        print(\"Cifar10 Downloaded Successfully...\")\n",
        "\n",
        "        # Extract the zip file\n",
        "        with tarfile.open(downloaded_file_path, \"r:gz\") as f:\n",
        "            f.extractall(self.root)\n",
        "\n",
        "        # delete the zip file\n",
        "        os.remove(downloaded_file_path)\n",
        "\n",
        "        print(\"Cifar10 Extracted Successfully...\")\n",
        "\n",
        "\n",
        "    def unpickle(self, file):\n",
        "        \"\"\"\n",
        "        This function helps in converting compressedfile into usable dictionary\n",
        "        \"\"\"\n",
        "        import pickle\n",
        "        with open(file, 'rb') as fo:\n",
        "            dict = pickle.load(fo, encoding='bytes')\n",
        "        return dict\n",
        "\n",
        "    def format_image(self, image, size=(3,32,32)):\n",
        "        \"\"\"\n",
        "        This function helps us with transforming our image\n",
        "        \"\"\"\n",
        "        image = image.reshape(size)\n",
        "\n",
        "        if self.transforms:\n",
        "            for transform in self.transforms:\n",
        "                image = transform(image)\n",
        "        return image\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdZ0EZZhCEJn"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "output = LoadCifar10(root=\"/content/drive/MyDrive/Deep Learning/CIFAR_10\", train=True, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXQ-q_CQSDAq",
        "outputId": "91f12ed5-d31f-462b-bee2-32f8bf52d455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[[0.6980, 0.7059, 0.6941,  ..., 0.4392, 0.4392, 0.4039],\n",
            "         [0.6902, 0.6980, 0.6863,  ..., 0.4196, 0.4000, 0.3765],\n",
            "         [0.7412, 0.7490, 0.7373,  ..., 0.4196, 0.3961, 0.3608]],\n",
            "\n",
            "        [[0.6980, 0.7020, 0.6941,  ..., 0.4431, 0.4392, 0.3922],\n",
            "         [0.6902, 0.6941, 0.6863,  ..., 0.4275, 0.4039, 0.3647],\n",
            "         [0.7412, 0.7451, 0.7373,  ..., 0.4235, 0.4000, 0.3529]],\n",
            "\n",
            "        [[0.6980, 0.7059, 0.6980,  ..., 0.4471, 0.4431, 0.4039],\n",
            "         [0.6902, 0.6980, 0.6902,  ..., 0.4314, 0.4039, 0.3725],\n",
            "         [0.7412, 0.7490, 0.7412,  ..., 0.4314, 0.4039, 0.3686]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.6667, 0.6784, 0.6706,  ..., 0.3922, 0.4000, 0.3608],\n",
            "         [0.6588, 0.6706, 0.6627,  ..., 0.3804, 0.3725, 0.3294],\n",
            "         [0.7059, 0.7137, 0.7059,  ..., 0.3686, 0.3647, 0.3137]],\n",
            "\n",
            "        [[0.6588, 0.6706, 0.6627,  ..., 0.3843, 0.4000, 0.3647],\n",
            "         [0.6510, 0.6627, 0.6549,  ..., 0.3686, 0.3647, 0.3373],\n",
            "         [0.6941, 0.7059, 0.6980,  ..., 0.3647, 0.3569, 0.3137]],\n",
            "\n",
            "        [[0.6471, 0.6588, 0.6549,  ..., 0.3961, 0.4000, 0.3569],\n",
            "         [0.6392, 0.6510, 0.6471,  ..., 0.3725, 0.3608, 0.3294],\n",
            "         [0.6824, 0.6941, 0.6902,  ..., 0.3725, 0.3569, 0.3020]]]), 0)\n"
          ]
        }
      ],
      "source": [
        "print(output.__str__()[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}